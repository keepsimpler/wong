{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp resnetx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from wong.imports import *\n",
    "from wong.core import *\n",
    "from wong.config import cfg, assert_cfg\n",
    "\n",
    "from torchvision.models.utils import load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_pred(l:int, start_id:int, d:int=1):\n",
    "    \"get predecessor layer id.\"\n",
    "    assert l >= 1 and start_id >= d\n",
    "    if l < start_id or d == 1:  # if the current layer index is less than the fold depth, or if fold depth == 1\n",
    "        pred = l - 1\n",
    "    else:\n",
    "        remainder = (l-1-(start_id-d)) % (d-1)\n",
    "        pred = l - 2 * (1+remainder)\n",
    "#         if remainder == 0:\n",
    "#             pred = l - 2 * (d-1)\n",
    "#         else:\n",
    "#             pred = l - 2 * remainder\n",
    "#         remainder1 = l % (2*(d-1))\n",
    "#         if 1 <= remainder1 <= d-1:\n",
    "#             pred = l - 2 * remainder1\n",
    "#         else:\n",
    "#             remainder2 = (remainder1 + d-1) % (2*(d-1))\n",
    "#             pred = l - 2 * remainder2\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "- l : current layer id.\n",
    "- start_id : index of the starting node\n",
    "- d : fold depth.\n",
    "\n",
    "Return:\n",
    "- The previous layer id that directly link to the current layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(l=50, start_id=8, d=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_pred(l=12, start_id=1, d=1), 11)\n",
    "\n",
    "test_eq(get_pred(l=8, start_id=7, d=5), 4)\n",
    "test_eq(get_pred(l=12, start_id=6, d=4), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def layer_diff(cur:int, pred:int, num_nodes:tuple):\n",
    "    \"layer difference between the current layer and the predecessor layer.\"\n",
    "    assert cur > pred\n",
    "    num_nodes = (1,) + num_nodes\n",
    "    cumsum = 0  # start with 0\n",
    "    for i, num in enumerate(num_nodes):\n",
    "        if cumsum <= cur < cumsum + num:\n",
    "            cur_layer = i\n",
    "        if cumsum <= pred < cumsum + num:\n",
    "            pred_layer = i\n",
    "        cumsum += num\n",
    "    diff = cur_layer - pred_layer\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = (3,4,6,3)\n",
    "cur, pred = 4,0\n",
    "layer_diff(cur, pred, num_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "- Stem : the stemming stage, which accept original images, transform them, then input into the backbone network.\n",
    "- Unit : the operation at nodes.\n",
    "- fold : the fold depth\n",
    "- ni : number of input channels of the backbone network.\n",
    "- *num_stages : number of stages in the backbone network.*\n",
    "- num_nodes : number of nodes of every stage in the backbone network.\n",
    "- start_id : index of starting node of ResNetX\n",
    "- base : standard width of channels in the backbone network.\n",
    "- exp : expansion along with the increase of stages.\n",
    "- bottle_scale : bottleneck scale\n",
    "- first_downsample: dose down-sample at the start of the first stage.\n",
    "- deep_stem : using 7x7 or 3 3x3 conv in stemming stage.\n",
    "- c_in : number of input channels of the Start layer\n",
    "- c_out : number of classes in the output of the final classifier.\n",
    "- kwargs : arguments translate into `Unit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNetX(nn.Module):\n",
    "    \"A folded resnet.\"\n",
    "    def __init__(self, Stem, Unit, fold:int, ni:int, num_nodes:tuple, start_id:int=0, base:int=64, exp:int=2, \n",
    "                 bottle_scale:int=1, first_downsample:bool=False, deep_stem:bool=False,\n",
    "                 c_in:int=3, c_out:int=10, **kwargs):\n",
    "        super(ResNetX, self).__init__()\n",
    "        # fold depth should be less than the sum length of any two neighboring stages\n",
    "        \n",
    "        if start_id < fold: start_id = fold\n",
    "        origin_ni = ni\n",
    "        num_stages = len(num_nodes)\n",
    "        nhs = [base * exp ** i for i in range(num_stages)] \n",
    "        nos = [nh * bottle_scale for nh in nhs]\n",
    "        strides = [1 if i==0 and not first_downsample else 2 for i in range(num_stages)]\n",
    "#         print('nhs=', nhs, 'nos=', nos, 'nus=', nus, 'strides=', strides)\n",
    "        \n",
    "        self.stem = Stem(c_in, ni, deep_stem)\n",
    "        \n",
    "        units = []\n",
    "        idmappings = []\n",
    "        cur = 1\n",
    "        for i, (nh, no, nu, stride) in enumerate(zip(nhs, nos, num_nodes, strides)):\n",
    "            for j in range(nu):\n",
    "                if j == 0: # the first node(layer) of each stage\n",
    "                    units += [Unit(ni, no, nh, stride=stride, **kwargs)]\n",
    "                else:\n",
    "                    units += [Unit(no, no, nh, stride=1, **kwargs)]\n",
    "                    \n",
    "                pred = get_pred(cur, start_id, fold) # \n",
    "                diff = layer_diff(cur, pred, num_nodes)\n",
    "                assert diff == 0 or diff == 1 or (diff == 2 and pred == 0), \\\n",
    "                       'cur={}, pred={}, diff={} is not allowed.'.format(cur, pred, diff)\n",
    "                print('cur = {} , pred = {} ,diff = {}'.format(cur, pred, diff))\n",
    "                if diff == 0:\n",
    "                    idmappings += [IdentityMapping(no, no, stride=1)]\n",
    "                elif diff == 1:\n",
    "                    idmappings += [IdentityMapping(ni, no, stride=stride)]\n",
    "                elif diff == 2:\n",
    "                    idmappings += [IdentityMapping(origin_ni, no, stride=stride)]\n",
    "                cur += 1\n",
    "            ni = no\n",
    "        self.units = nn.ModuleList(units)\n",
    "        self.idmappings = nn.ModuleList(idmappings)\n",
    "        \n",
    "        self.classifier = Classifier(nos[-1], c_out)\n",
    "        self.start_id, self.fold = start_id, fold\n",
    "        self.num_nodes, self.deep_stem = num_nodes, deep_stem\n",
    "        init_cnn(self)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        results = {}\n",
    "        results[0] = self.stem(x)\n",
    "        cur = 0\n",
    "        for i, (unit, idmapping) in enumerate(zip(self.units, self.idmappings)):\n",
    "            cur += 1\n",
    "            pred = get_pred(cur, self.start_id, self.fold)\n",
    "            results[cur % (2*self.fold-1)] = unit(results[(cur-1) % (2*self.fold-1)]) + idmapping(results[pred % (2*self.fold-1)])\n",
    "        x = results[cur % (2*self.fold-1)]\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        \n",
    "    def load_state_dict(self, state_dict, local_to_pretrained):\n",
    "        error_msgs = []\n",
    "        def load(module, prefix=''):\n",
    "            local_name_params = itertools.chain(module._parameters.items(), module._buffers.items())\n",
    "            local_state = {k: v.data for k, v in local_name_params if v is not None}\n",
    "\n",
    "            new_prefix = local_to_pretrained.get(prefix, 'none')\n",
    "            for name, param in local_state.items():\n",
    "                key = new_prefix + name\n",
    "                if key in state_dict:\n",
    "                    print(key)\n",
    "                    input_param = state_dict[key]\n",
    "\n",
    "                    if input_param.shape != param.shape:\n",
    "                        # local shape should match the one in checkpoint\n",
    "                        error_msgs.append('size mismatch for {}: copying a param with shape {} from checkpoint, '\n",
    "                                          'the shape in current model is {}.'\n",
    "                                          .format(key, input_param.shape, param.shape))\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        param.copy_(input_param)\n",
    "                    except Exception:\n",
    "                        error_msgs.append('While copying the parameter named \"{}\", '\n",
    "                                          'whose dimensions in the model are {} and '\n",
    "                                          'whose dimensions in the checkpoint are {}.'\n",
    "                                          .format(key, param.size(), input_param.size()))\n",
    "                    \n",
    "            for name, child in module._modules.items():\n",
    "                if child is not None:\n",
    "                    load(child, prefix + name + '.')\n",
    "        load(self)\n",
    "        load = None # break load->load reference cycle\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet_local_to_pretrained(num_nodes, start_id, fold):\n",
    "    local_to_pretrained = {  # mapping from the names of local modules to the names of pretrained modules\n",
    "        'stem.0.': 'conv1.',\n",
    "        'stem.1.': 'bn1.',\n",
    "    }\n",
    "\n",
    "    cumsum = 0\n",
    "    for i, num in enumerate(num_nodes):\n",
    "        for j in range(num):\n",
    "            key = 'units.' + str(cumsum + j) + '.'\n",
    "            value = 'layer' + str(i+1) + '.' + str(j) + '.'\n",
    "            downsample0 = 'layer' + str(i+1) + '.0.' + 'downsample.0.'\n",
    "            downsample1 = 'layer' + str(i+1) + '.0.' + 'downsample.1.'\n",
    "\n",
    "            pred = get_pred(cumsum + j + 1, start_id, fold) # \n",
    "            diff = layer_diff(cumsum + j + 1, pred, num_nodes)\n",
    "            if diff == 1:\n",
    "                idmapping0 = 'idmappings.' + str(cumsum + j) + '.unit.0.'\n",
    "                idmapping1 = 'idmappings.' + str(cumsum + j) + '.unit.1.'\n",
    "#                     print(idmapping0, downsample0)\n",
    "#                     print(idmapping1, downsample1)\n",
    "                local_to_pretrained[idmapping0] = downsample0\n",
    "                local_to_pretrained[idmapping1] = downsample1\n",
    "\n",
    "            for a, b in zip(['1.','2.','4.','5.','7.','8.'], ['conv1.','bn1.','conv2.','bn2.','conv3.','bn3.']):\n",
    "#                     print (key + a, value + b)\n",
    "                local_to_pretrained[key + a] = value + b\n",
    "\n",
    "        cumsum += num\n",
    "    \n",
    "    return local_to_pretrained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnetx152(cfg_file:str, fold:int, start_id:int, pretrained:bool=False):\n",
    "    cfg.merge_from_file(cfg_file)\n",
    "    assert_cfg(cfg)\n",
    "    cfg.freeze()\n",
    "    Stem = getattr(sys.modules[__name__], cfg.GRAPH.STEM)\n",
    "    Unit = getattr(sys.modules[__name__], cfg.GRAPH.UNIT)\n",
    "    # start_id >= fold + 1, fold <= 6\n",
    "    model = ResNetX(Stem = Stem, Unit = Unit, fold=fold, ni=cfg.GRAPH.NI, num_nodes=cfg.GRAPH.NUM_NODES, \n",
    "                    start_id=start_id, base=cfg.GRAPH.BASE, exp=cfg.GRAPH.EXP, bottle_scale=cfg.GRAPH.BOTTLE_SCALE,\n",
    "                    first_downsample=cfg.GRAPH.FIRST_DOWNSAMPLE, deep_stem=cfg.GRAPH.DEEP_STEM)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(cfg.URL)\n",
    "        local_to_pretrained = resnet_local_to_pretrained(cfg.GRAPH.NUM_NODES,start_id, fold)\n",
    "        model.load_state_dict(state_dict, local_to_pretrained)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur = 1 , pred = 0 ,diff = 1\n",
      "cur = 2 , pred = 1 ,diff = 0\n",
      "cur = 3 , pred = 2 ,diff = 0\n",
      "cur = 4 , pred = 3 ,diff = 1\n",
      "cur = 5 , pred = 4 ,diff = 0\n",
      "cur = 6 , pred = 5 ,diff = 0\n",
      "cur = 7 , pred = 6 ,diff = 0\n",
      "cur = 8 , pred = 7 ,diff = 0\n",
      "cur = 9 , pred = 8 ,diff = 0\n",
      "cur = 10 , pred = 9 ,diff = 0\n",
      "cur = 11 , pred = 10 ,diff = 0\n",
      "cur = 12 , pred = 11 ,diff = 1\n",
      "cur = 13 , pred = 12 ,diff = 0\n",
      "cur = 14 , pred = 13 ,diff = 0\n",
      "cur = 15 , pred = 14 ,diff = 0\n",
      "cur = 16 , pred = 15 ,diff = 0\n",
      "cur = 17 , pred = 16 ,diff = 0\n",
      "cur = 18 , pred = 17 ,diff = 0\n",
      "cur = 19 , pred = 18 ,diff = 0\n",
      "cur = 20 , pred = 19 ,diff = 0\n",
      "cur = 21 , pred = 20 ,diff = 0\n",
      "cur = 22 , pred = 21 ,diff = 0\n",
      "cur = 23 , pred = 22 ,diff = 0\n",
      "cur = 24 , pred = 23 ,diff = 0\n",
      "cur = 25 , pred = 24 ,diff = 0\n",
      "cur = 26 , pred = 25 ,diff = 0\n",
      "cur = 27 , pred = 26 ,diff = 0\n",
      "cur = 28 , pred = 27 ,diff = 0\n",
      "cur = 29 , pred = 28 ,diff = 0\n",
      "cur = 30 , pred = 29 ,diff = 0\n",
      "cur = 31 , pred = 30 ,diff = 0\n",
      "cur = 32 , pred = 31 ,diff = 0\n",
      "cur = 33 , pred = 32 ,diff = 0\n",
      "cur = 34 , pred = 33 ,diff = 0\n",
      "cur = 35 , pred = 34 ,diff = 0\n",
      "cur = 36 , pred = 35 ,diff = 0\n",
      "cur = 37 , pred = 36 ,diff = 0\n",
      "cur = 38 , pred = 37 ,diff = 0\n",
      "cur = 39 , pred = 38 ,diff = 0\n",
      "cur = 40 , pred = 39 ,diff = 0\n",
      "cur = 41 , pred = 40 ,diff = 0\n",
      "cur = 42 , pred = 41 ,diff = 0\n",
      "cur = 43 , pred = 42 ,diff = 0\n",
      "cur = 44 , pred = 43 ,diff = 0\n",
      "cur = 45 , pred = 44 ,diff = 0\n",
      "cur = 46 , pred = 45 ,diff = 0\n",
      "cur = 47 , pred = 46 ,diff = 0\n",
      "cur = 48 , pred = 47 ,diff = 1\n",
      "cur = 49 , pred = 48 ,diff = 0\n",
      "cur = 50 , pred = 49 ,diff = 0\n",
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "bn1.running_mean\n",
      "bn1.running_var\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.bn1.running_mean\n",
      "layer1.0.bn1.running_var\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.bn2.running_mean\n",
      "layer1.0.bn2.running_var\n",
      "layer1.0.conv3.weight\n",
      "layer1.0.bn3.weight\n",
      "layer1.0.bn3.bias\n",
      "layer1.0.bn3.running_mean\n",
      "layer1.0.bn3.running_var\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.bn1.running_mean\n",
      "layer1.1.bn1.running_var\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.bn2.running_mean\n",
      "layer1.1.bn2.running_var\n",
      "layer1.1.conv3.weight\n",
      "layer1.1.bn3.weight\n",
      "layer1.1.bn3.bias\n",
      "layer1.1.bn3.running_mean\n",
      "layer1.1.bn3.running_var\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.bn1.running_mean\n",
      "layer1.2.bn1.running_var\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer1.2.bn2.running_mean\n",
      "layer1.2.bn2.running_var\n",
      "layer1.2.conv3.weight\n",
      "layer1.2.bn3.weight\n",
      "layer1.2.bn3.bias\n",
      "layer1.2.bn3.running_mean\n",
      "layer1.2.bn3.running_var\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.bn1.running_mean\n",
      "layer2.0.bn1.running_var\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.bn2.running_mean\n",
      "layer2.0.bn2.running_var\n",
      "layer2.0.conv3.weight\n",
      "layer2.0.bn3.weight\n",
      "layer2.0.bn3.bias\n",
      "layer2.0.bn3.running_mean\n",
      "layer2.0.bn3.running_var\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.bn1.running_mean\n",
      "layer2.1.bn1.running_var\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.bn2.running_mean\n",
      "layer2.1.bn2.running_var\n",
      "layer2.1.conv3.weight\n",
      "layer2.1.bn3.weight\n",
      "layer2.1.bn3.bias\n",
      "layer2.1.bn3.running_mean\n",
      "layer2.1.bn3.running_var\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.bn1.running_mean\n",
      "layer2.2.bn1.running_var\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.2.bn2.running_mean\n",
      "layer2.2.bn2.running_var\n",
      "layer2.2.conv3.weight\n",
      "layer2.2.bn3.weight\n",
      "layer2.2.bn3.bias\n",
      "layer2.2.bn3.running_mean\n",
      "layer2.2.bn3.running_var\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.bn1.running_mean\n",
      "layer2.3.bn1.running_var\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer2.3.bn2.running_mean\n",
      "layer2.3.bn2.running_var\n",
      "layer2.3.conv3.weight\n",
      "layer2.3.bn3.weight\n",
      "layer2.3.bn3.bias\n",
      "layer2.3.bn3.running_mean\n",
      "layer2.3.bn3.running_var\n",
      "layer2.4.conv1.weight\n",
      "layer2.4.bn1.weight\n",
      "layer2.4.bn1.bias\n",
      "layer2.4.bn1.running_mean\n",
      "layer2.4.bn1.running_var\n",
      "layer2.4.conv2.weight\n",
      "layer2.4.bn2.weight\n",
      "layer2.4.bn2.bias\n",
      "layer2.4.bn2.running_mean\n",
      "layer2.4.bn2.running_var\n",
      "layer2.4.conv3.weight\n",
      "layer2.4.bn3.weight\n",
      "layer2.4.bn3.bias\n",
      "layer2.4.bn3.running_mean\n",
      "layer2.4.bn3.running_var\n",
      "layer2.5.conv1.weight\n",
      "layer2.5.bn1.weight\n",
      "layer2.5.bn1.bias\n",
      "layer2.5.bn1.running_mean\n",
      "layer2.5.bn1.running_var\n",
      "layer2.5.conv2.weight\n",
      "layer2.5.bn2.weight\n",
      "layer2.5.bn2.bias\n",
      "layer2.5.bn2.running_mean\n",
      "layer2.5.bn2.running_var\n",
      "layer2.5.conv3.weight\n",
      "layer2.5.bn3.weight\n",
      "layer2.5.bn3.bias\n",
      "layer2.5.bn3.running_mean\n",
      "layer2.5.bn3.running_var\n",
      "layer2.6.conv1.weight\n",
      "layer2.6.bn1.weight\n",
      "layer2.6.bn1.bias\n",
      "layer2.6.bn1.running_mean\n",
      "layer2.6.bn1.running_var\n",
      "layer2.6.conv2.weight\n",
      "layer2.6.bn2.weight\n",
      "layer2.6.bn2.bias\n",
      "layer2.6.bn2.running_mean\n",
      "layer2.6.bn2.running_var\n",
      "layer2.6.conv3.weight\n",
      "layer2.6.bn3.weight\n",
      "layer2.6.bn3.bias\n",
      "layer2.6.bn3.running_mean\n",
      "layer2.6.bn3.running_var\n",
      "layer2.7.conv1.weight\n",
      "layer2.7.bn1.weight\n",
      "layer2.7.bn1.bias\n",
      "layer2.7.bn1.running_mean\n",
      "layer2.7.bn1.running_var\n",
      "layer2.7.conv2.weight\n",
      "layer2.7.bn2.weight\n",
      "layer2.7.bn2.bias\n",
      "layer2.7.bn2.running_mean\n",
      "layer2.7.bn2.running_var\n",
      "layer2.7.conv3.weight\n",
      "layer2.7.bn3.weight\n",
      "layer2.7.bn3.bias\n",
      "layer2.7.bn3.running_mean\n",
      "layer2.7.bn3.running_var\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.bn1.running_mean\n",
      "layer3.0.bn1.running_var\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.bn2.running_mean\n",
      "layer3.0.bn2.running_var\n",
      "layer3.0.conv3.weight\n",
      "layer3.0.bn3.weight\n",
      "layer3.0.bn3.bias\n",
      "layer3.0.bn3.running_mean\n",
      "layer3.0.bn3.running_var\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.bn1.running_mean\n",
      "layer3.1.bn1.running_var\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.bn2.running_mean\n",
      "layer3.1.bn2.running_var\n",
      "layer3.1.conv3.weight\n",
      "layer3.1.bn3.weight\n",
      "layer3.1.bn3.bias\n",
      "layer3.1.bn3.running_mean\n",
      "layer3.1.bn3.running_var\n",
      "layer3.2.conv1.weight\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.bn1.running_mean\n",
      "layer3.2.bn1.running_var\n",
      "layer3.2.conv2.weight\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.2.bn2.running_mean\n",
      "layer3.2.bn2.running_var\n",
      "layer3.2.conv3.weight\n",
      "layer3.2.bn3.weight\n",
      "layer3.2.bn3.bias\n",
      "layer3.2.bn3.running_mean\n",
      "layer3.2.bn3.running_var\n",
      "layer3.3.conv1.weight\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.bn1.running_mean\n",
      "layer3.3.bn1.running_var\n",
      "layer3.3.conv2.weight\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.3.bn2.running_mean\n",
      "layer3.3.bn2.running_var\n",
      "layer3.3.conv3.weight\n",
      "layer3.3.bn3.weight\n",
      "layer3.3.bn3.bias\n",
      "layer3.3.bn3.running_mean\n",
      "layer3.3.bn3.running_var\n",
      "layer3.4.conv1.weight\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.bn1.running_mean\n",
      "layer3.4.bn1.running_var\n",
      "layer3.4.conv2.weight\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.4.bn2.running_mean\n",
      "layer3.4.bn2.running_var\n",
      "layer3.4.conv3.weight\n",
      "layer3.4.bn3.weight\n",
      "layer3.4.bn3.bias\n",
      "layer3.4.bn3.running_mean\n",
      "layer3.4.bn3.running_var\n",
      "layer3.5.conv1.weight\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.bn1.running_mean\n",
      "layer3.5.bn1.running_var\n",
      "layer3.5.conv2.weight\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer3.5.bn2.running_mean\n",
      "layer3.5.bn2.running_var\n",
      "layer3.5.conv3.weight\n",
      "layer3.5.bn3.weight\n",
      "layer3.5.bn3.bias\n",
      "layer3.5.bn3.running_mean\n",
      "layer3.5.bn3.running_var\n",
      "layer3.6.conv1.weight\n",
      "layer3.6.bn1.weight\n",
      "layer3.6.bn1.bias\n",
      "layer3.6.bn1.running_mean\n",
      "layer3.6.bn1.running_var\n",
      "layer3.6.conv2.weight\n",
      "layer3.6.bn2.weight\n",
      "layer3.6.bn2.bias\n",
      "layer3.6.bn2.running_mean\n",
      "layer3.6.bn2.running_var\n",
      "layer3.6.conv3.weight\n",
      "layer3.6.bn3.weight\n",
      "layer3.6.bn3.bias\n",
      "layer3.6.bn3.running_mean\n",
      "layer3.6.bn3.running_var\n",
      "layer3.7.conv1.weight\n",
      "layer3.7.bn1.weight\n",
      "layer3.7.bn1.bias\n",
      "layer3.7.bn1.running_mean\n",
      "layer3.7.bn1.running_var\n",
      "layer3.7.conv2.weight\n",
      "layer3.7.bn2.weight\n",
      "layer3.7.bn2.bias\n",
      "layer3.7.bn2.running_mean\n",
      "layer3.7.bn2.running_var\n",
      "layer3.7.conv3.weight\n",
      "layer3.7.bn3.weight\n",
      "layer3.7.bn3.bias\n",
      "layer3.7.bn3.running_mean\n",
      "layer3.7.bn3.running_var\n",
      "layer3.8.conv1.weight\n",
      "layer3.8.bn1.weight\n",
      "layer3.8.bn1.bias\n",
      "layer3.8.bn1.running_mean\n",
      "layer3.8.bn1.running_var\n",
      "layer3.8.conv2.weight\n",
      "layer3.8.bn2.weight\n",
      "layer3.8.bn2.bias\n",
      "layer3.8.bn2.running_mean\n",
      "layer3.8.bn2.running_var\n",
      "layer3.8.conv3.weight\n",
      "layer3.8.bn3.weight\n",
      "layer3.8.bn3.bias\n",
      "layer3.8.bn3.running_mean\n",
      "layer3.8.bn3.running_var\n",
      "layer3.9.conv1.weight\n",
      "layer3.9.bn1.weight\n",
      "layer3.9.bn1.bias\n",
      "layer3.9.bn1.running_mean\n",
      "layer3.9.bn1.running_var\n",
      "layer3.9.conv2.weight\n",
      "layer3.9.bn2.weight\n",
      "layer3.9.bn2.bias\n",
      "layer3.9.bn2.running_mean\n",
      "layer3.9.bn2.running_var\n",
      "layer3.9.conv3.weight\n",
      "layer3.9.bn3.weight\n",
      "layer3.9.bn3.bias\n",
      "layer3.9.bn3.running_mean\n",
      "layer3.9.bn3.running_var\n",
      "layer3.10.conv1.weight\n",
      "layer3.10.bn1.weight\n",
      "layer3.10.bn1.bias\n",
      "layer3.10.bn1.running_mean\n",
      "layer3.10.bn1.running_var\n",
      "layer3.10.conv2.weight\n",
      "layer3.10.bn2.weight\n",
      "layer3.10.bn2.bias\n",
      "layer3.10.bn2.running_mean\n",
      "layer3.10.bn2.running_var\n",
      "layer3.10.conv3.weight\n",
      "layer3.10.bn3.weight\n",
      "layer3.10.bn3.bias\n",
      "layer3.10.bn3.running_mean\n",
      "layer3.10.bn3.running_var\n",
      "layer3.11.conv1.weight\n",
      "layer3.11.bn1.weight\n",
      "layer3.11.bn1.bias\n",
      "layer3.11.bn1.running_mean\n",
      "layer3.11.bn1.running_var\n",
      "layer3.11.conv2.weight\n",
      "layer3.11.bn2.weight\n",
      "layer3.11.bn2.bias\n",
      "layer3.11.bn2.running_mean\n",
      "layer3.11.bn2.running_var\n",
      "layer3.11.conv3.weight\n",
      "layer3.11.bn3.weight\n",
      "layer3.11.bn3.bias\n",
      "layer3.11.bn3.running_mean\n",
      "layer3.11.bn3.running_var\n",
      "layer3.12.conv1.weight\n",
      "layer3.12.bn1.weight\n",
      "layer3.12.bn1.bias\n",
      "layer3.12.bn1.running_mean\n",
      "layer3.12.bn1.running_var\n",
      "layer3.12.conv2.weight\n",
      "layer3.12.bn2.weight\n",
      "layer3.12.bn2.bias\n",
      "layer3.12.bn2.running_mean\n",
      "layer3.12.bn2.running_var\n",
      "layer3.12.conv3.weight\n",
      "layer3.12.bn3.weight\n",
      "layer3.12.bn3.bias\n",
      "layer3.12.bn3.running_mean\n",
      "layer3.12.bn3.running_var\n",
      "layer3.13.conv1.weight\n",
      "layer3.13.bn1.weight\n",
      "layer3.13.bn1.bias\n",
      "layer3.13.bn1.running_mean\n",
      "layer3.13.bn1.running_var\n",
      "layer3.13.conv2.weight\n",
      "layer3.13.bn2.weight\n",
      "layer3.13.bn2.bias\n",
      "layer3.13.bn2.running_mean\n",
      "layer3.13.bn2.running_var\n",
      "layer3.13.conv3.weight\n",
      "layer3.13.bn3.weight\n",
      "layer3.13.bn3.bias\n",
      "layer3.13.bn3.running_mean\n",
      "layer3.13.bn3.running_var\n",
      "layer3.14.conv1.weight\n",
      "layer3.14.bn1.weight\n",
      "layer3.14.bn1.bias\n",
      "layer3.14.bn1.running_mean\n",
      "layer3.14.bn1.running_var\n",
      "layer3.14.conv2.weight\n",
      "layer3.14.bn2.weight\n",
      "layer3.14.bn2.bias\n",
      "layer3.14.bn2.running_mean\n",
      "layer3.14.bn2.running_var\n",
      "layer3.14.conv3.weight\n",
      "layer3.14.bn3.weight\n",
      "layer3.14.bn3.bias\n",
      "layer3.14.bn3.running_mean\n",
      "layer3.14.bn3.running_var\n",
      "layer3.15.conv1.weight\n",
      "layer3.15.bn1.weight\n",
      "layer3.15.bn1.bias\n",
      "layer3.15.bn1.running_mean\n",
      "layer3.15.bn1.running_var\n",
      "layer3.15.conv2.weight\n",
      "layer3.15.bn2.weight\n",
      "layer3.15.bn2.bias\n",
      "layer3.15.bn2.running_mean\n",
      "layer3.15.bn2.running_var\n",
      "layer3.15.conv3.weight\n",
      "layer3.15.bn3.weight\n",
      "layer3.15.bn3.bias\n",
      "layer3.15.bn3.running_mean\n",
      "layer3.15.bn3.running_var\n",
      "layer3.16.conv1.weight\n",
      "layer3.16.bn1.weight\n",
      "layer3.16.bn1.bias\n",
      "layer3.16.bn1.running_mean\n",
      "layer3.16.bn1.running_var\n",
      "layer3.16.conv2.weight\n",
      "layer3.16.bn2.weight\n",
      "layer3.16.bn2.bias\n",
      "layer3.16.bn2.running_mean\n",
      "layer3.16.bn2.running_var\n",
      "layer3.16.conv3.weight\n",
      "layer3.16.bn3.weight\n",
      "layer3.16.bn3.bias\n",
      "layer3.16.bn3.running_mean\n",
      "layer3.16.bn3.running_var\n",
      "layer3.17.conv1.weight\n",
      "layer3.17.bn1.weight\n",
      "layer3.17.bn1.bias\n",
      "layer3.17.bn1.running_mean\n",
      "layer3.17.bn1.running_var\n",
      "layer3.17.conv2.weight\n",
      "layer3.17.bn2.weight\n",
      "layer3.17.bn2.bias\n",
      "layer3.17.bn2.running_mean\n",
      "layer3.17.bn2.running_var\n",
      "layer3.17.conv3.weight\n",
      "layer3.17.bn3.weight\n",
      "layer3.17.bn3.bias\n",
      "layer3.17.bn3.running_mean\n",
      "layer3.17.bn3.running_var\n",
      "layer3.18.conv1.weight\n",
      "layer3.18.bn1.weight\n",
      "layer3.18.bn1.bias\n",
      "layer3.18.bn1.running_mean\n",
      "layer3.18.bn1.running_var\n",
      "layer3.18.conv2.weight\n",
      "layer3.18.bn2.weight\n",
      "layer3.18.bn2.bias\n",
      "layer3.18.bn2.running_mean\n",
      "layer3.18.bn2.running_var\n",
      "layer3.18.conv3.weight\n",
      "layer3.18.bn3.weight\n",
      "layer3.18.bn3.bias\n",
      "layer3.18.bn3.running_mean\n",
      "layer3.18.bn3.running_var\n",
      "layer3.19.conv1.weight\n",
      "layer3.19.bn1.weight\n",
      "layer3.19.bn1.bias\n",
      "layer3.19.bn1.running_mean\n",
      "layer3.19.bn1.running_var\n",
      "layer3.19.conv2.weight\n",
      "layer3.19.bn2.weight\n",
      "layer3.19.bn2.bias\n",
      "layer3.19.bn2.running_mean\n",
      "layer3.19.bn2.running_var\n",
      "layer3.19.conv3.weight\n",
      "layer3.19.bn3.weight\n",
      "layer3.19.bn3.bias\n",
      "layer3.19.bn3.running_mean\n",
      "layer3.19.bn3.running_var\n",
      "layer3.20.conv1.weight\n",
      "layer3.20.bn1.weight\n",
      "layer3.20.bn1.bias\n",
      "layer3.20.bn1.running_mean\n",
      "layer3.20.bn1.running_var\n",
      "layer3.20.conv2.weight\n",
      "layer3.20.bn2.weight\n",
      "layer3.20.bn2.bias\n",
      "layer3.20.bn2.running_mean\n",
      "layer3.20.bn2.running_var\n",
      "layer3.20.conv3.weight\n",
      "layer3.20.bn3.weight\n",
      "layer3.20.bn3.bias\n",
      "layer3.20.bn3.running_mean\n",
      "layer3.20.bn3.running_var\n",
      "layer3.21.conv1.weight\n",
      "layer3.21.bn1.weight\n",
      "layer3.21.bn1.bias\n",
      "layer3.21.bn1.running_mean\n",
      "layer3.21.bn1.running_var\n",
      "layer3.21.conv2.weight\n",
      "layer3.21.bn2.weight\n",
      "layer3.21.bn2.bias\n",
      "layer3.21.bn2.running_mean\n",
      "layer3.21.bn2.running_var\n",
      "layer3.21.conv3.weight\n",
      "layer3.21.bn3.weight\n",
      "layer3.21.bn3.bias\n",
      "layer3.21.bn3.running_mean\n",
      "layer3.21.bn3.running_var\n",
      "layer3.22.conv1.weight\n",
      "layer3.22.bn1.weight\n",
      "layer3.22.bn1.bias\n",
      "layer3.22.bn1.running_mean\n",
      "layer3.22.bn1.running_var\n",
      "layer3.22.conv2.weight\n",
      "layer3.22.bn2.weight\n",
      "layer3.22.bn2.bias\n",
      "layer3.22.bn2.running_mean\n",
      "layer3.22.bn2.running_var\n",
      "layer3.22.conv3.weight\n",
      "layer3.22.bn3.weight\n",
      "layer3.22.bn3.bias\n",
      "layer3.22.bn3.running_mean\n",
      "layer3.22.bn3.running_var\n",
      "layer3.23.conv1.weight\n",
      "layer3.23.bn1.weight\n",
      "layer3.23.bn1.bias\n",
      "layer3.23.bn1.running_mean\n",
      "layer3.23.bn1.running_var\n",
      "layer3.23.conv2.weight\n",
      "layer3.23.bn2.weight\n",
      "layer3.23.bn2.bias\n",
      "layer3.23.bn2.running_mean\n",
      "layer3.23.bn2.running_var\n",
      "layer3.23.conv3.weight\n",
      "layer3.23.bn3.weight\n",
      "layer3.23.bn3.bias\n",
      "layer3.23.bn3.running_mean\n",
      "layer3.23.bn3.running_var\n",
      "layer3.24.conv1.weight\n",
      "layer3.24.bn1.weight\n",
      "layer3.24.bn1.bias\n",
      "layer3.24.bn1.running_mean\n",
      "layer3.24.bn1.running_var\n",
      "layer3.24.conv2.weight\n",
      "layer3.24.bn2.weight\n",
      "layer3.24.bn2.bias\n",
      "layer3.24.bn2.running_mean\n",
      "layer3.24.bn2.running_var\n",
      "layer3.24.conv3.weight\n",
      "layer3.24.bn3.weight\n",
      "layer3.24.bn3.bias\n",
      "layer3.24.bn3.running_mean\n",
      "layer3.24.bn3.running_var\n",
      "layer3.25.conv1.weight\n",
      "layer3.25.bn1.weight\n",
      "layer3.25.bn1.bias\n",
      "layer3.25.bn1.running_mean\n",
      "layer3.25.bn1.running_var\n",
      "layer3.25.conv2.weight\n",
      "layer3.25.bn2.weight\n",
      "layer3.25.bn2.bias\n",
      "layer3.25.bn2.running_mean\n",
      "layer3.25.bn2.running_var\n",
      "layer3.25.conv3.weight\n",
      "layer3.25.bn3.weight\n",
      "layer3.25.bn3.bias\n",
      "layer3.25.bn3.running_mean\n",
      "layer3.25.bn3.running_var\n",
      "layer3.26.conv1.weight\n",
      "layer3.26.bn1.weight\n",
      "layer3.26.bn1.bias\n",
      "layer3.26.bn1.running_mean\n",
      "layer3.26.bn1.running_var\n",
      "layer3.26.conv2.weight\n",
      "layer3.26.bn2.weight\n",
      "layer3.26.bn2.bias\n",
      "layer3.26.bn2.running_mean\n",
      "layer3.26.bn2.running_var\n",
      "layer3.26.conv3.weight\n",
      "layer3.26.bn3.weight\n",
      "layer3.26.bn3.bias\n",
      "layer3.26.bn3.running_mean\n",
      "layer3.26.bn3.running_var\n",
      "layer3.27.conv1.weight\n",
      "layer3.27.bn1.weight\n",
      "layer3.27.bn1.bias\n",
      "layer3.27.bn1.running_mean\n",
      "layer3.27.bn1.running_var\n",
      "layer3.27.conv2.weight\n",
      "layer3.27.bn2.weight\n",
      "layer3.27.bn2.bias\n",
      "layer3.27.bn2.running_mean\n",
      "layer3.27.bn2.running_var\n",
      "layer3.27.conv3.weight\n",
      "layer3.27.bn3.weight\n",
      "layer3.27.bn3.bias\n",
      "layer3.27.bn3.running_mean\n",
      "layer3.27.bn3.running_var\n",
      "layer3.28.conv1.weight\n",
      "layer3.28.bn1.weight\n",
      "layer3.28.bn1.bias\n",
      "layer3.28.bn1.running_mean\n",
      "layer3.28.bn1.running_var\n",
      "layer3.28.conv2.weight\n",
      "layer3.28.bn2.weight\n",
      "layer3.28.bn2.bias\n",
      "layer3.28.bn2.running_mean\n",
      "layer3.28.bn2.running_var\n",
      "layer3.28.conv3.weight\n",
      "layer3.28.bn3.weight\n",
      "layer3.28.bn3.bias\n",
      "layer3.28.bn3.running_mean\n",
      "layer3.28.bn3.running_var\n",
      "layer3.29.conv1.weight\n",
      "layer3.29.bn1.weight\n",
      "layer3.29.bn1.bias\n",
      "layer3.29.bn1.running_mean\n",
      "layer3.29.bn1.running_var\n",
      "layer3.29.conv2.weight\n",
      "layer3.29.bn2.weight\n",
      "layer3.29.bn2.bias\n",
      "layer3.29.bn2.running_mean\n",
      "layer3.29.bn2.running_var\n",
      "layer3.29.conv3.weight\n",
      "layer3.29.bn3.weight\n",
      "layer3.29.bn3.bias\n",
      "layer3.29.bn3.running_mean\n",
      "layer3.29.bn3.running_var\n",
      "layer3.30.conv1.weight\n",
      "layer3.30.bn1.weight\n",
      "layer3.30.bn1.bias\n",
      "layer3.30.bn1.running_mean\n",
      "layer3.30.bn1.running_var\n",
      "layer3.30.conv2.weight\n",
      "layer3.30.bn2.weight\n",
      "layer3.30.bn2.bias\n",
      "layer3.30.bn2.running_mean\n",
      "layer3.30.bn2.running_var\n",
      "layer3.30.conv3.weight\n",
      "layer3.30.bn3.weight\n",
      "layer3.30.bn3.bias\n",
      "layer3.30.bn3.running_mean\n",
      "layer3.30.bn3.running_var\n",
      "layer3.31.conv1.weight\n",
      "layer3.31.bn1.weight\n",
      "layer3.31.bn1.bias\n",
      "layer3.31.bn1.running_mean\n",
      "layer3.31.bn1.running_var\n",
      "layer3.31.conv2.weight\n",
      "layer3.31.bn2.weight\n",
      "layer3.31.bn2.bias\n",
      "layer3.31.bn2.running_mean\n",
      "layer3.31.bn2.running_var\n",
      "layer3.31.conv3.weight\n",
      "layer3.31.bn3.weight\n",
      "layer3.31.bn3.bias\n",
      "layer3.31.bn3.running_mean\n",
      "layer3.31.bn3.running_var\n",
      "layer3.32.conv1.weight\n",
      "layer3.32.bn1.weight\n",
      "layer3.32.bn1.bias\n",
      "layer3.32.bn1.running_mean\n",
      "layer3.32.bn1.running_var\n",
      "layer3.32.conv2.weight\n",
      "layer3.32.bn2.weight\n",
      "layer3.32.bn2.bias\n",
      "layer3.32.bn2.running_mean\n",
      "layer3.32.bn2.running_var\n",
      "layer3.32.conv3.weight\n",
      "layer3.32.bn3.weight\n",
      "layer3.32.bn3.bias\n",
      "layer3.32.bn3.running_mean\n",
      "layer3.32.bn3.running_var\n",
      "layer3.33.conv1.weight\n",
      "layer3.33.bn1.weight\n",
      "layer3.33.bn1.bias\n",
      "layer3.33.bn1.running_mean\n",
      "layer3.33.bn1.running_var\n",
      "layer3.33.conv2.weight\n",
      "layer3.33.bn2.weight\n",
      "layer3.33.bn2.bias\n",
      "layer3.33.bn2.running_mean\n",
      "layer3.33.bn2.running_var\n",
      "layer3.33.conv3.weight\n",
      "layer3.33.bn3.weight\n",
      "layer3.33.bn3.bias\n",
      "layer3.33.bn3.running_mean\n",
      "layer3.33.bn3.running_var\n",
      "layer3.34.conv1.weight\n",
      "layer3.34.bn1.weight\n",
      "layer3.34.bn1.bias\n",
      "layer3.34.bn1.running_mean\n",
      "layer3.34.bn1.running_var\n",
      "layer3.34.conv2.weight\n",
      "layer3.34.bn2.weight\n",
      "layer3.34.bn2.bias\n",
      "layer3.34.bn2.running_mean\n",
      "layer3.34.bn2.running_var\n",
      "layer3.34.conv3.weight\n",
      "layer3.34.bn3.weight\n",
      "layer3.34.bn3.bias\n",
      "layer3.34.bn3.running_mean\n",
      "layer3.34.bn3.running_var\n",
      "layer3.35.conv1.weight\n",
      "layer3.35.bn1.weight\n",
      "layer3.35.bn1.bias\n",
      "layer3.35.bn1.running_mean\n",
      "layer3.35.bn1.running_var\n",
      "layer3.35.conv2.weight\n",
      "layer3.35.bn2.weight\n",
      "layer3.35.bn2.bias\n",
      "layer3.35.bn2.running_mean\n",
      "layer3.35.bn2.running_var\n",
      "layer3.35.conv3.weight\n",
      "layer3.35.bn3.weight\n",
      "layer3.35.bn3.bias\n",
      "layer3.35.bn3.running_mean\n",
      "layer3.35.bn3.running_var\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.bn1.running_mean\n",
      "layer4.0.bn1.running_var\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.bn2.running_mean\n",
      "layer4.0.bn2.running_var\n",
      "layer4.0.conv3.weight\n",
      "layer4.0.bn3.weight\n",
      "layer4.0.bn3.bias\n",
      "layer4.0.bn3.running_mean\n",
      "layer4.0.bn3.running_var\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.bn1.running_mean\n",
      "layer4.1.bn1.running_var\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.bn2.running_mean\n",
      "layer4.1.bn2.running_var\n",
      "layer4.1.conv3.weight\n",
      "layer4.1.bn3.weight\n",
      "layer4.1.bn3.bias\n",
      "layer4.1.bn3.running_mean\n",
      "layer4.1.bn3.running_var\n",
      "layer4.2.conv1.weight\n",
      "layer4.2.bn1.weight\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.bn1.running_mean\n",
      "layer4.2.bn1.running_var\n",
      "layer4.2.conv2.weight\n",
      "layer4.2.bn2.weight\n",
      "layer4.2.bn2.bias\n",
      "layer4.2.bn2.running_mean\n",
      "layer4.2.bn2.running_var\n",
      "layer4.2.conv3.weight\n",
      "layer4.2.bn3.weight\n",
      "layer4.2.bn3.bias\n",
      "layer4.2.bn3.running_mean\n",
      "layer4.2.bn3.running_var\n",
      "layer1.0.downsample.0.weight\n",
      "layer1.0.downsample.1.weight\n",
      "layer1.0.downsample.1.bias\n",
      "layer1.0.downsample.1.running_mean\n",
      "layer1.0.downsample.1.running_var\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.0.downsample.1.running_mean\n",
      "layer2.0.downsample.1.running_var\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.0.downsample.1.running_mean\n",
      "layer3.0.downsample.1.running_var\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.0.downsample.1.running_mean\n",
      "layer4.0.downsample.1.running_var\n"
     ]
    }
   ],
   "source": [
    "cfg_file = 'configs/imagenet/resnet/resnet152.yaml'\n",
    "model = resnetx152(cfg_file, fold=1, start_id=1, pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip : Three methods to get `class` or `function` object from its string name:\n",
    "- `getattr(sys.modules[__name__], cfg.GRAPH.STEM)`\n",
    "- `globals()[cfg.GRAPH.STEM]`\n",
    "- `eval(cfg.GRAPH.STEM)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    out = model(x)\n",
    "    out.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64,894,538'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:,}\".format(num_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_resnet152 = resnet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torchvision.models.resnet'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
