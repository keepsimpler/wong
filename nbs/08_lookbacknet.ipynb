{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp lookbacknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from wong.imports import *\n",
    "from wong.core import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LookbackBlock(nn.Module):\n",
    "    \"Basic block of lookback ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold:int, stride:int=1, **kwargs):\n",
    "        super(LookbackBlock, self).__init__()\n",
    "        self.ni, self.fold, self.stride = ni, fold, stride\n",
    "        units = []\n",
    "        for i in range(fold):\n",
    "            units += [Unit(ni, stride=1, **kwargs)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        \n",
    "    def forward(self, *xs):\n",
    "        xs = list(xs)\n",
    "        for i in range(self.fold):\n",
    "            xs[i] = xs[i] + self.units[i](xs[i-1])\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, [torch.Size([2, 16, 32, 32]), torch.Size([2, 16, 32, 32])])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold=2\n",
    "m = LookbackBlock(mbconv, ni=16, fold=fold, nh=32)\n",
    "\n",
    "xs = [torch.randn(2,16,32,32)] * fold\n",
    "\n",
    "xs2 = m(*xs)\n",
    "\n",
    "len(xs2), [x.shape for x in xs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExpandBlock(nn.Module):\n",
    "    \"Expand block of lookback ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold1:int, fold2:int, stride:int=1, **kwargs):\n",
    "        super(ExpandBlock, self).__init__()\n",
    "        self.ni, self.fold1, self.fold2, self.stride = ni, fold1, fold2, stride\n",
    "        units = []\n",
    "        for i in range(fold2 - fold1):\n",
    "            units += [Unit(ni, stride=1, **kwargs)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        if stride == 2:\n",
    "            self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, *xs):\n",
    "        xs = list(xs)\n",
    "        if self.stride == 2:\n",
    "            for i in range(len(xs)):\n",
    "                xs[i] = self.pool(xs[i])\n",
    "        if self.fold2 <= self.fold1:\n",
    "            return xs[:self.fold2]\n",
    "        for i in range(self.fold2 - self.fold1):\n",
    "            xs.append(self.units[i](xs[-1]) + xs[-1])\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ExpandBlock(mbconv, ni=16, fold1=fold, fold2=3, stride=2, nh=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs2 = m(*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " [torch.Size([2, 16, 16, 16]),\n",
       "  torch.Size([2, 16, 16, 16]),\n",
       "  torch.Size([2, 16, 16, 16])])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs2), [x.shape for x in xs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LookbackNet(nn.Module):\n",
    "    \"A lookback resnet, using Expand.\"\n",
    "    def __init__(self, Stem, Unit, folds:tuple, ni:int, num_nodes:tuple,\n",
    "                 bottle_scale:int=1, first_downsample:bool=False, tail_all:bool=True,\n",
    "                 c_in:int=3, c_out:int=10, **kwargs):\n",
    "        super(LookbackNet, self).__init__()\n",
    "        num_stages = len(num_nodes)\n",
    "        nh = int(ni * bottle_scale)\n",
    "        strides = [1 if i==0 and not first_downsample else 2 for i in range(num_stages)]\n",
    "#         folds = [1] + folds #[fold*exp**i for i in range(num_stages)]\n",
    "        \n",
    "        self.stem = Stem(c_in, no=ni) # , deep_stem\n",
    "        \n",
    "        units = []\n",
    "        for i, (nu, stride) in enumerate(zip(num_nodes, strides)):\n",
    "            for j in range(nu):\n",
    "                if j == 0 and i != 0: # the first node(layer) of each stage\n",
    "                    units += [ExpandBlock(Unit, ni, fold1 = folds[i-1], fold2=folds[i], stride=stride, nh=nh, **kwargs)]\n",
    "                else:\n",
    "                    units += [LookbackBlock(Unit, ni, fold=folds[i], stride=1, nh=nh, **kwargs)]\n",
    "                    \n",
    "        self.units = nn.ModuleList(units)\n",
    "        \n",
    "        if tail_all:\n",
    "            self.classifier = Classifier(ni*folds[-1], c_out) #\n",
    "        else:\n",
    "            self.classifier = Classifier(ni, c_out)\n",
    "        self.folds = folds\n",
    "        self.num_nodes = num_nodes\n",
    "        self.tail_all = tail_all\n",
    "        init_cnn(self)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        xs = [x] * self.folds[0]\n",
    "        for unit in self.units:\n",
    "            xs = unit(*xs)\n",
    "        if self.tail_all:\n",
    "            x = torch.cat(xs,1)\n",
    "        else:\n",
    "            x = xs[0]\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1199012)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = [8,9,9,9]\n",
    "folds = [4,4,4,4]\n",
    "ni = 64\n",
    "bottle_scale = 1\n",
    "model = LookbackNet(Stem=conv_bn, Unit=mbconv, folds=folds, ni=ni, num_nodes=num_nodes, \n",
    "                bottle_scale=bottle_scale, tail_all=True, ks=3, c_out=100, zero_bn=True)\n",
    "num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    out = model(x)\n",
    "    out.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
