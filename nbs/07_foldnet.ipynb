{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp foldnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from wong.imports import *\n",
    "from wong.core import *\n",
    "from wong.config import cfg, assert_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *  # test_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FoldNet\n",
    "> a folded ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate to enough units for folded net:\n",
    "1. Unit : unit operator\n",
    "2. ni : number of input channels for `Unit`\n",
    "3. fold : folding length\n",
    "4. stride : across stage or not\n",
    "5. **kwargs : arguments to `Unit`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# class FoldBlock(nn.Module):\n",
    "#     \"Basic block of folded ResNet\"\n",
    "#     def __init__(self, Unit:nn.Module, ni:int, fold:int, stride:int=1, **kwargs):\n",
    "#         super(FoldBlock, self).__init__()\n",
    "#         self.ni, self.fold, self.stride = ni, fold, stride\n",
    "#         units = []\n",
    "#         for i in range(max(1,fold-1)):\n",
    "#             units += [Unit(ni, stride=1, **kwargs)]\n",
    "#         self.units = nn.ModuleList(units)\n",
    "        \n",
    "#     def forward(self, *xs):\n",
    "#         xs = list(xs)\n",
    "#         if self.fold==1:\n",
    "#             xs[0] = xs[0] + self.units[0](xs[0])\n",
    "#             return xs\n",
    "#         for i in range(self.fold-1):\n",
    "#             xs[i+1] = xs[i] + self.units[i](xs[i+1])\n",
    "#         xs.reverse()\n",
    "#         return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FoldBlock(nn.Module):\n",
    "    \"Basic block of folded ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold:int, stride:int=1, **kwargs):\n",
    "        super(FoldBlock, self).__init__()\n",
    "        self.ni, self.fold, self.stride = ni, fold, stride\n",
    "        units = []\n",
    "        for i in range(max(1,fold-1)):\n",
    "            units += [Unit(ni, stride=1, **kwargs)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        \n",
    "    def forward(self, *xs):\n",
    "        xs = list(xs)\n",
    "        if self.fold==1:\n",
    "            xs[0] = xs[0] + self.units[0](xs[0])\n",
    "            return xs\n",
    "        for i in range(self.fold-1):\n",
    "            xs[i+1] = xs[i+1] + self.units[i](xs[i])\n",
    "        xs.reverse()\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " [torch.Size([2, 16, 32, 32]),\n",
       "  torch.Size([2, 16, 32, 32]),\n",
       "  torch.Size([2, 16, 32, 32]),\n",
       "  torch.Size([2, 16, 32, 32])])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = FoldBlock(mbconv, 16, 4, nh=32)\n",
    "\n",
    "xs = [torch.randn(2,16,32,32)] * 4\n",
    "\n",
    "xs2 = m(*xs)\n",
    "\n",
    "len(xs2), [x.shape for x in xs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExpandBlock(nn.Module):\n",
    "    \"Expand block of folded ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold1:int, fold2:int, stride:int=1, **kwargs):\n",
    "        super(ExpandBlock, self).__init__()\n",
    "        self.ni, self.fold1, self.fold2, self.stride = ni, fold1, fold2, stride\n",
    "        units = []\n",
    "        for i in range(fold2 - fold1):\n",
    "            units += [Unit(ni, stride=1, **kwargs)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        if stride == 2:\n",
    "            self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, *xs):\n",
    "        xs = list(xs)\n",
    "        if self.stride == 2:\n",
    "            for i in range(len(xs)):\n",
    "                xs[i] = self.pool(xs[i])\n",
    "        if self.fold2 <= self.fold1:\n",
    "            return xs[:self.fold2]\n",
    "        xs.reverse()\n",
    "        for i in range(self.fold2 - self.fold1):\n",
    "            xs.append(self.units[i](xs[-1]) + xs[-1])\n",
    "        xs.reverse()\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ExpandBlock(mbconv, 16, fold1=4, fold2=3, stride=2, nh=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs2 = m(*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " [torch.Size([2, 16, 16, 16]),\n",
       "  torch.Size([2, 16, 16, 16]),\n",
       "  torch.Size([2, 16, 16, 16])])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs2), [x.shape for x in xs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FoldNet(nn.Module):\n",
    "    \"A folded resnet, using Expand.\"\n",
    "    def __init__(self, Stem, Unit, folds:tuple, ni:int, num_nodes:tuple,\n",
    "                 bottle_scale:int=1, first_downsample:bool=False, tail_all:bool=True,\n",
    "                 c_in:int=3, c_out:int=10, **kwargs):\n",
    "        super(FoldNet, self).__init__()\n",
    "        num_stages = len(num_nodes)\n",
    "        nh = int(ni * bottle_scale)\n",
    "        strides = [1 if i==0 and not first_downsample else 2 for i in range(num_stages)]\n",
    "        folds = [1] + folds #[fold*exp**i for i in range(num_stages)]\n",
    "        \n",
    "        self.stem = Stem(c_in, no=ni) # , deep_stem\n",
    "        \n",
    "        units = []\n",
    "        for i, (nu, stride) in enumerate(zip(num_nodes, strides)):\n",
    "            for j in range(nu):\n",
    "                if j == 0: # the first node(layer) of each stage\n",
    "                    units += [ExpandBlock(Unit, ni, fold1 = folds[i], fold2=folds[i+1], stride=stride, nh=nh, **kwargs)]\n",
    "                else:\n",
    "                    units += [FoldBlock(Unit, ni, fold=folds[i+1], stride=1, nh=nh, **kwargs)]\n",
    "                    \n",
    "        self.units = nn.ModuleList(units)\n",
    "        \n",
    "        if tail_all:\n",
    "            self.classifier = Classifier(ni*folds[-1], c_out) #\n",
    "        else:\n",
    "            self.classifier = Classifier(ni, c_out)\n",
    "        self.folds = folds\n",
    "        self.num_nodes = num_nodes\n",
    "        self.tail_all = tail_all\n",
    "        init_cnn(self)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        xs = [x] #self.init(x)\n",
    "        for unit in self.units:\n",
    "            xs = unit(*xs)\n",
    "        if self.tail_all:\n",
    "            x = torch.cat(xs,1)\n",
    "        else:\n",
    "            x = xs[0]\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(906148)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = [8,9,9,9]\n",
    "folds = [4,4,4,4]\n",
    "model = FoldNet(Stem=conv_bn, Unit=mbconv, folds=folds, ni=64, num_nodes=num_nodes, bottle_scale=1, tail_all=True, ks=3, c_out=100)\n",
    "num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    out = model(x)\n",
    "    out.mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate number of params in FoldNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def num_units(folds, nodes):\n",
    "    \"calculate the number of all units in the backbone of FoldNet.\"\n",
    "    num_units = (folds[0] - 1) * nodes[0]\n",
    "    for i in range(len(folds)-1):\n",
    "#         print(num_units)\n",
    "        num_units += (folds[i+1]-1)*(nodes[i+1]-1) + max(0, folds[i+1]-folds[i])\n",
    "    return(num_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the folding length of stage $i$ is $d_i$, then the number of units per FoldNet block is $d_i-1$.Suppose the number of blocks per stage is $b_i$, then the number of units of stage $i$ equal to $(d_i-1) * (b_i-1)$ for all the stages except the first stage, since a `ExpandBlock` with none unit start at each stage except the first stage.\n",
    "\n",
    "Suppose $n$ stages exist, then the number of all units in the backbone of FoldNet is:\n",
    "\\begin{equation}\n",
    "(d_0-1) * b_0 + \\sum_1^{n-1} (d_i-1) * (b_i-1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cal_num_params(Stem, Unit, folds, nodes, ni, bottle_scale, tail_all, c_out):\n",
    "    \"calcuate the number of all params of FoldNet, according to hyper-params.\"\n",
    "    m0 = Stem(3, no=ni)\n",
    "    m1 = Unit(ni, nh=ni*bottle_scale)\n",
    "    m2 = Classifier(ni*folds[-1] if tail_all else ni, c_out)\n",
    "    return num_params(m0) + num_params(m1) * num_units(folds, nodes) + num_params(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(906148)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#folds = [fold]*4\n",
    "cal_num_params(Stem=conv_bn, Unit=mbconv, folds=folds, nodes=num_nodes, ni=64, bottle_scale=1, tail_all=True, c_out=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "class InitBlock(nn.Module):\n",
    "    \"Init block of folded ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold:int, stride:int=1, **kwargs):\n",
    "        super(InitBlock, self).__init__()\n",
    "        self.ni, self.fold = ni, fold\n",
    "        units = []\n",
    "        for i in range(fold-1):\n",
    "            units += [Unit(ni, stride=stride, **kwargs)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xs = [x]\n",
    "        for i in range(self.fold-1):\n",
    "            xs += [xs[i] + self.units[i](xs[i])]\n",
    "        xs.reverse()\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([2, 16, 32, 32]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "m = InitBlock(mbconv, 16, 4, stride=1, nh=32)\n",
    "x = torch.randn(2,16,32,32)\n",
    "xs = m(x)\n",
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# try inner fold (fold before BN), may fail\n",
    "class FoldBlock2(nn.Module):\n",
    "    \"Basic block of folded ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold:int, stride:int=1, **kwargs):\n",
    "        super(FoldBlock2, self).__init__()\n",
    "        self.ni, self.fold, self.stride = ni, fold, stride\n",
    "        units = []\n",
    "        aggregates = []\n",
    "        for i in range(fold-1):\n",
    "            units += [Unit(ni, stride=1, **kwargs)]\n",
    "            aggregates += [conv_bn(ni, ks=1, zero_bn=False)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        self.aggregates = nn.ModuleList(aggregates)\n",
    "        \n",
    "    def forward(self, *xs):\n",
    "        xs = list(xs)\n",
    "        for i in range(self.fold-1):\n",
    "            xs[i+1] = xs[i+1] + self.units[i](xs[i])\n",
    "        for i in range(self.fold-1):\n",
    "            xs[i+1] = self.aggregates[i](xs[i+1])\n",
    "        xs.reverse()\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# try particular transition block, may fail\n",
    "class TransitionBlock(nn.Module):\n",
    "    \"Transition block of folded ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, no:int, fold:int, stride:int=1, **kwargs):\n",
    "        super(TransitionBlock, self).__init__()\n",
    "        self.ni, self.no, self.fold, self.stride = ni, no, fold, stride\n",
    "        units = []\n",
    "        idmappings = []\n",
    "        for i in range(fold-1):\n",
    "            if i==0:\n",
    "                units += [Unit(ni, no=no, stride=stride, **kwargs)]\n",
    "            else:\n",
    "                units += [Unit(ni=no, no=no, stride=1, **kwargs)]\n",
    "            idmappings += [IdentityMappingMaxPool(ni, no=no, stride=stride)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        self.idmappings = nn.ModuleList(idmappings)\n",
    "        self.idmapping0 = IdentityMappingMaxPool(ni, no=no, stride=stride)\n",
    "        \n",
    "    def forward(self, *xs):\n",
    "        xs = list(xs)\n",
    "        for i in range(self.fold-1):\n",
    "            xs[i+1] = self.idmappings[i](xs[i+1]) + self.units[i](xs[i])\n",
    "        xs[0] = self.idmapping0(xs[0])\n",
    "        xs.reverse()\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "m = TransitionBlock(mbconv, ni=16, no=32, fold=4, stride=2, nh=32)\n",
    "\n",
    "[x.shape for x in xs]\n",
    "\n",
    "xs2 = m(*xs)\n",
    "\n",
    "len(xs2), [x.shape for x in xs2]\n",
    "\n",
    "isinstance(m, TransitionBlock), isinstance(m, ExpandBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# try particular transition block, may fail\n",
    "class ResNetXTransition(nn.Module):\n",
    "    \"A folded resnet using Transition.\"\n",
    "    def __init__(self, Stem, Unit, fold:int, nis:tuple, num_nodes:tuple,\n",
    "                 bottle_scale:int=1, first_downsample:bool=False, tail_all:bool=True,\n",
    "                 c_in:int=3, c_out:int=10, **kwargs):\n",
    "        super(ResNetXTransition, self).__init__()\n",
    "        num_stages = len(num_nodes)\n",
    "        nhs = [int(ni * bottle_scale) for ni in nis]\n",
    "        strides = [1 if i==0 and not first_downsample else 2 for i in range(num_stages)]\n",
    "        \n",
    "        self.stem = Stem(c_in, no=nis[0]) # , deep_stem\n",
    "        self.expand = ExpandBlock(Unit, ni=nis[0], fold1=1, fold2=fold, stride=strides[0], nh=nhs[0], **kwargs)\n",
    "        \n",
    "        units = []\n",
    "        for i, (nu, stride) in enumerate(zip(num_nodes, strides)):\n",
    "            if i != 0:\n",
    "                units += [TransitionBlock(Unit, ni=nis[i-1], no=nis[i], fold=fold, stride=stride, nh=nhs[i-1], **kwargs)]\n",
    "            for j in range(nu):\n",
    "#                 if j == 0: # the first node(layer) of each stage\n",
    "#                     units += [ExpandBlock(Unit, ni, fold1 = folds[i], fold2=folds[i+1], stride=stride, nh=nh, **kwargs)]\n",
    "#                 else:\n",
    "                units += [FoldBlock(Unit, ni=nis[i], fold=fold, stride=1, nh=nhs[i], **kwargs)]\n",
    "                    \n",
    "        self.units = nn.ModuleList(units)\n",
    "        \n",
    "        if tail_all:\n",
    "            self.classifier = Classifier(nis[-1]*fold, c_out) #\n",
    "        else:\n",
    "            self.classifier = Classifier(nis[-1], c_out)\n",
    "        self.fold = fold\n",
    "        self.num_nodes = num_nodes\n",
    "        self.tail_all = tail_all\n",
    "        init_cnn(self)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        xs = self.expand(*[x])\n",
    "        for unit in self.units:\n",
    "            xs = unit(*xs)\n",
    "        if self.tail_all:\n",
    "            x = torch.cat(xs,1)\n",
    "        else:\n",
    "            x = xs[0]\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5620548)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "num_nodes = [4,4,4,4]\n",
    "fold = 4\n",
    "nis = [32,64,96,128]\n",
    "bottle_scale = 6\n",
    "model = ResNetXTransition(Stem=conv_bn, Unit=mbconv, fold=fold, nis=nis, num_nodes=num_nodes,\n",
    "                          bottle_scale=bottle_scale, tail_all=False, ks=3, c_out=100)\n",
    "num_params(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
