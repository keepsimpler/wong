{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from wong.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "> All the basic functions and classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze-Excite Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ShuffleBlock(nn.Module):\n",
    "    def __init__(self, groups):\n",
    "        super(ShuffleBlock, self).__init__()\n",
    "        self.groups = groups\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]'''\n",
    "        N, C, H, W = x.size()\n",
    "        g = self.groups\n",
    "        return x.view(N, g, C//g, H, W).permute(0, 2, 1, 3, 4).reshape(N, C, H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OprtType(Enum):\n",
    "    \"Operator types.`Nothing` means not any operator there.\"\n",
    "    Nothing = 0\n",
    "    Conv2d  = 1\n",
    "    ReLU = 2\n",
    "    BatchNorm2d = 3\n",
    "    Shuffle = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_unit(ni:int, seq:tuple, no:int=None, ks:int=3, stride:int=1, groups:int=1, zero_bn:bool=False, act_inplace:bool=True):\n",
    "    \"\"\"\n",
    "    The basic convolutional operation, which is combination of operators such as conv, bn, relu, etc.\n",
    "    \"\"\"\n",
    "    if no is None: no = ni\n",
    "    unit = []\n",
    "    has_conv = False # if has conv operator\n",
    "    for e in seq:\n",
    "        if e == OprtType.Nothing:  # None operator\n",
    "            continue\n",
    "        elif e == OprtType.Conv2d:  # conv operator\n",
    "            has_conv = True\n",
    "            unit += [nn.Conv2d(ni, no, ks, stride=stride, padding=ks//2, groups=groups, bias=False)]\n",
    "        elif e == OprtType.ReLU:  # relu operator\n",
    "            unit += [nn.ReLU(inplace=act_inplace)]  # in folded resnet, inplace has to be false\n",
    "        elif e == OprtType.BatchNorm2d:  # bn operator\n",
    "            if has_conv: # if has conv operator\n",
    "                bn = nn.BatchNorm2d(no)  # bn operator's `ni` equal to 'no' of conv op\n",
    "                nn.init.constant_(bn.weight, 0. if zero_bn else 1.) # zero bn only after conv\n",
    "                unit += [bn]\n",
    "            else:  # if has not conv operator\n",
    "                unit += [nn.BatchNorm2d(ni)] # bn operator's `ni` equal to 'ni' of conv op\n",
    "        elif e == OprtType.Shuffle:  # Shuffle operator\n",
    "            unit += [ShuffleBlock(groups)]\n",
    "    return nn.Sequential(*unit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "- `ni` : number of input channels\n",
    "- `seq` : sequence of operators, a tuple of `OprtType` operator types\n",
    "- `no` : number of output channels\n",
    "- `ks` : kernel size of conv operator\n",
    "- `stride` : stride size of conv operator\n",
    "- `groups` : number of groups of conv operator\n",
    "- `zero_bn` : does initialize zero value for weight of batch norm operator\n",
    "- `act_inplace` : does do the activations in-place.\n",
    "\n",
    "Return:\n",
    "- a nn.Sequential object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "conv = partial(conv_unit, seq = (OprtType.Conv2d, OprtType.Nothing, OprtType.Nothing))  # Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(16, no=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"several customized conv units\"\n",
    "relu_conv_bn = partial(conv_unit, seq = (OprtType.ReLU, OprtType.Conv2d, OprtType.BatchNorm2d))  # Relu-->Conv-->BN\n",
    "conv_bn_relu = partial(conv_unit, seq = (OprtType.Conv2d, OprtType.BatchNorm2d, OprtType.ReLU))  # Conv-->BN-->Relu\n",
    "bn_relu_conv = partial(conv_unit, seq = (OprtType.BatchNorm2d, OprtType.ReLU, OprtType.Conv2d))  # BN-->Relu-->Conv\n",
    "relu_conv = partial(conv_unit, seq = (OprtType.ReLU, OprtType.Conv2d, OprtType.Nothing))  # Relu-->Conv\n",
    "conv_bn = partial(conv_unit, seq = (OprtType.Conv2d, OprtType.BatchNorm2d, OprtType.Nothing))  # Conv-->BN\n",
    "\n",
    "relu_conv_bn_shuffle = partial(conv_unit, seq = (OprtType.ReLU, OprtType.Conv2d, OprtType.BatchNorm2d, OprtType.Shuffle))  # Relu-->Conv-->BN-->Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*conv_bn(16,no=16,ks=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pack_relu_conv_bn(ni, no, nh, stride:int=1, groups:int=1, zero_bn:bool=True):\n",
    "    \"Packed relu_conv_bn unit\"\n",
    "    return relu_conv_bn(ni, no=no, stride=stride, groups=groups, zero_bn=zero_bn)\n",
    "\n",
    "def pack_bn_relu_conv(ni, no, nh, stride:int=1, groups:int=1, zero_bn:bool=True):\n",
    "    \"\"\"\"\"\"\n",
    "    return bn_relu_conv(ni, no=no, stride=stride, groups=groups, zero_bn=zero_bn)\n",
    "\n",
    "def pack_relu_conv_bn_shuffle(ni, no, nh, stride:int=1, groups:int=1, zero_bn:bool=True):\n",
    "    \"\"\"\"\"\"\n",
    "    return relu_conv_bn_shuffle(ni, no=no, stride=stride, groups=groups, zero_bn=zero_bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet_basicblock(ni, no, nh, stride:int=1):\n",
    "    \"\"\"\n",
    "    Basic Unit in Residual Networks\n",
    "    \n",
    "    Reference:\n",
    "    Deep Residual Learning for Image Recognition:\n",
    "    https://arxiv.org/abs/1512.03385\n",
    "    \"\"\"\n",
    "    return nn.Sequential(*relu_conv_bn(ni, no=nh, stride=stride), \n",
    "                         *relu_conv_bn(nh, no=no))\n",
    "\n",
    "def resnet_bottleneck(ni, no, nh, stride:int=1, groups:int=1, zero_bn=True):\n",
    "    \"\"\"\n",
    "    Bottleneck Unit in Residual Networks\n",
    "    \n",
    "    Reference:\n",
    "    Deep Residual Learning for Image Recognition:\n",
    "    https://arxiv.org/abs/1512.03385\n",
    "    \"\"\"\n",
    "    return nn.Sequential(*relu_conv_bn(ni, no=nh, ks=1),\n",
    "                         *relu_conv_bn(nh, no=nh, stride=stride, groups=groups),\n",
    "                         *relu_conv_bn(nh, no=no, ks=1, zero_bn=zero_bn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): ReLU(inplace=True)\n",
       "   (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (3): ReLU(inplace=True)\n",
       "   (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), Sequential(\n",
       "   (0): ReLU(inplace=True)\n",
       "   (1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (3): ReLU(inplace=True)\n",
       "   (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (6): ReLU(inplace=True)\n",
       "   (7): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_basicblock(16, 16, 16), resnet_bottleneck(16,16,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# residential block\n",
    "def preresnet_basicblock(ni, no, nh, stride:int=1):\n",
    "    \"\"\"\n",
    "    Basic Unit in Pre-action Residual Networks, ni == no == nh\n",
    "    \n",
    "    Reference:\n",
    "    ----------\n",
    "    Identity Mappings in Deep Residual Networks:\n",
    "    https://arxiv.org/abs/1603.05027\n",
    "    \"\"\"\n",
    "    return nn.Sequential(*bn_relu_conv(ni, no=nh, stride=stride), \n",
    "                         *bn_relu_conv(nh, no=no))\n",
    "\n",
    "def preresnet_bottleneck(ni, no, nh, stride:int=1, groups:int=1, zero_bn=True):\n",
    "    return nn.Sequential(*bn_relu_conv(ni, no=nh, ks=1),\n",
    "                         *bn_relu_conv(nh, no=nh, stride=stride, groups=groups),\n",
    "                         *bn_relu_conv(nh, no=no, ks=1, zero_bn=zero_bn))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (4): ReLU(inplace=True)\n",
       "   (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       " ), Sequential(\n",
       "   (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (4): ReLU(inplace=True)\n",
       "   (5): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (6): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (7): ReLU(inplace=True)\n",
       "   (8): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       " ))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preresnet_basicblock(16, 16, 16), preresnet_bottleneck(16,16,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def xception(ni:int, no:int, nh:int, ks:int=3, stride:int=1, zero_bn:bool=False):\n",
    "    \"\"\"\n",
    "    Basic unit in xception networks.\n",
    "    \n",
    "    Reference:\n",
    "    Xception: Deep Learning with Depthwise Separable Convolutions:\n",
    "    https://arxiv.org/abs/1610.02357\n",
    "    \"\"\"\n",
    "    return nn.Sequential(*relu_conv(ni, no=nh, ks=ks, stride=stride, groups=ni),\n",
    "                         *conv_bn(nh, no=no, ks=1, zero_bn=zero_bn)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mbconv(ni:int, no:int=None, nh:int=None, ks:int=3, stride:int=1, groups:int=None, zero_bn:bool=False):\n",
    "    \"Mobile Inverted Bottleneck block in MobileNetV2\"\n",
    "    if no is None: no = ni\n",
    "    if nh is None: nh = ni\n",
    "    if groups is None: groups = nh\n",
    "    return nn.Sequential(*conv_bn_relu(ni, no=nh, ks=1, stride=1),\n",
    "                         *conv_bn_relu(nh, no=nh, ks=ks, stride=stride, groups=groups),\n",
    "                         *conv_bn(nh, no=no, ks=1, stride=1, zero_bn=zero_bn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbconv(16, stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resnet_stem(ni:int=3, no:int=64):\n",
    "    stem = nn.Sequential(nn.Conv2d(ni, no, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "                         nn.BatchNorm2d(no),\n",
    "                         nn.ReLU(inplace=True),\n",
    "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    return stem\n",
    "\n",
    "def resnet_stem_deep(ni:int=3, no:int=64):\n",
    "    stem = nn.Sequential(*conv_bn_relu(ni, no=no, stride=2),  #downsample\n",
    "                         *conv_bn_relu(no, no=no, stride=1),\n",
    "                         *conv_bn_relu(no, no=no, stride=1),\n",
    "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "                 )\n",
    "    return stem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       "   (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       " ), Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       "   (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (5): ReLU(inplace=True)\n",
       "   (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (8): ReLU(inplace=True)\n",
       "   (9): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       " ))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_stem(), resnet_stem_deep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IdentityMappingMaxPool(nn.Module):\n",
    "    \"\"\"\n",
    "    Identity Mapping using maxpool to accross stage, four cases:\n",
    "    1.  stride == 1 and ni == no\n",
    "        input == output\n",
    "    2.  stride == 1 and ni != no\n",
    "        1x1 conv --> bn\n",
    "    3.  stride == 2 and ni == no\n",
    "        maxpool\n",
    "    4.  stride == 2 and ni != no\n",
    "        (maxpool) --> 1x1 conv --> bn\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, ni:int, no:int, stride:int=1):\n",
    "        super(IdentityMappingMaxPool, self).__init__()\n",
    "        assert stride == 1 or stride == 2\n",
    "        unit = []\n",
    "        if stride == 2:\n",
    "            downsample = nn.MaxPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "            unit.append(downsample)\n",
    "        if ni != no:\n",
    "            unit += conv_bn(ni, no=no, ks=1) #.children()  #, zero_bn=False\n",
    "        self.unit = nn.Sequential(*unit)\n",
    "    def forward(self, x):\n",
    "        out = self.unit(x)\n",
    "        return out\n",
    "    \n",
    "class IdentityMappingAvgPool(nn.Module):\n",
    "    \"\"\"\n",
    "    Identity Mapping using avgpool to accross stage, four cases:\n",
    "    1.  stride == 1 and ni == no\n",
    "        input == output\n",
    "    2.  stride == 1 and ni != no\n",
    "        1x1 conv --> bn\n",
    "    3.  stride == 2 and ni == no\n",
    "        avgpool\n",
    "    4.  stride == 2 and ni != no\n",
    "        (avgpool) --> 1x1 conv --> bn\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, ni:int, no:int, stride:int=1):\n",
    "        super(IdentityMappingAvgPool, self).__init__()\n",
    "        assert stride == 1 or stride == 2\n",
    "        unit = []\n",
    "        if stride == 2:\n",
    "            downsample = nn.AvgPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "            unit.append(downsample)\n",
    "        if ni != no:\n",
    "            unit += conv_bn(ni, no=no, ks=1) #.children()  #, zero_bn=False\n",
    "        self.unit = nn.Sequential(*unit)\n",
    "    def forward(self, x):\n",
    "        out = self.unit(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IdentityMapping(nn.Module):\n",
    "    \"\"\" Identity mapping of ResNet.        \n",
    "    Identity mapping of ResNet, two cases:\n",
    "    1.  stride == 1 and ni == no\n",
    "        input == output\n",
    "    2.  else\n",
    "        1x1 conv with stride --> bn\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, ni:int, no:int, stride:int=1):\n",
    "        super(IdentityMapping, self).__init__()\n",
    "        assert stride == 1 or stride == 2\n",
    "        unit = []\n",
    "        if not (ni == no and stride == 1):\n",
    "            unit += conv_bn(ni, no=no, ks=1, stride=stride) #.children()  #, zero_bn=False\n",
    "        self.unit = nn.Sequential(*unit)\n",
    "    def forward(self, x):\n",
    "        out = self.unit(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(IdentityMapping(\n",
       "   (unit): Sequential(\n",
       "     (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), IdentityMapping(\n",
       "   (unit): Sequential(\n",
       "     (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ), IdentityMapping(\n",
       "   (unit): Sequential()\n",
       " ), IdentityMapping(\n",
       "   (unit): Sequential(\n",
       "     (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IdentityMapping(16, 32, stride=2), IdentityMapping(16, 32, stride=1), \\\n",
    "IdentityMapping(16, 16, stride=1), IdentityMapping(16, 16, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = IdentityMapping(16, 16, stride=1)\n",
    "x = torch.randn(2,16,32,32)\n",
    "torch.all(m(x) == x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Usually work as the final operator for image processing (classification, object detection, etc.)\n",
    "    \n",
    "    Including:\n",
    "    an average pooling op, which downsampling image resolution to 1x1.\n",
    "    a linear op, which perform classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(ni, no)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.adaptivepool(x)  # out tensor (N, ni, 1, 1)\n",
    "        out = out.view(out.size(0), -1)  # out tensor (N, ni)\n",
    "        out = self.fc(out)  # out tensor (N, no)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ClassifierBNReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    Usually work as the final operator for image processing (classification, object detection, etc.)\n",
    "    \n",
    "    Including:\n",
    "    an average pooling op, which downsampling image resolution to 1x1.\n",
    "    a linear op, which perform classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no):\n",
    "        super(ClassifierBNReLU, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(ni)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(ni, no)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        out = self.adaptivepool(x)  # out tensor (N, ni, 1, 1)\n",
    "        out = out.view(out.size(0), -1)  # out tensor (N, ni)\n",
    "        out = self.fc(out)  # out tensor (N, no)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,16,8,8)\n",
    "m = ClassifierBNReLU(16, 32)\n",
    "m(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_cnn(m):\n",
    "    \"copy from https://github.com/fastai/fastai/blob/master/fastai/vision/models/xresnet.py\"\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def num_params(net:nn.Module):\n",
    "    \"Number of parameters of a neural network\"\n",
    "    num_params = 0\n",
    "    for name, param in net.named_parameters():\n",
    "        num = torch.prod(torch.tensor(param.size()))\n",
    "        num_params += num\n",
    "        # print(name, param.size(), num)\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
