{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp resnetx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from wong.imports import *\n",
    "from wong.core import *\n",
    "from wong.config import cfg, assert_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *  # test_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Init4(nn.Module):\n",
    "    \"Init block of folded ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold:int, **kwargs):\n",
    "        super(Init4, self).__init__()\n",
    "        unit1 = Unit(ni, stride=1, **kwargs)\n",
    "        unit2 = Unit(ni, stride=1, **kwargs)\n",
    "        unit3 = Unit(ni, stride=1, **kwargs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = unit1(x) + x\n",
    "        x2 = unit2(x1) + x1\n",
    "        x3 = unit3(x2) + x2\n",
    "        return x3, x2, x1, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNetX2\n",
    "> a folded ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate to enough units for folded net:\n",
    "1. Unit : unit operator\n",
    "2. ni : number of input channels for `Unit`\n",
    "3. fold : folding length\n",
    "4. stride : across stage or not\n",
    "5. **kwargs : arguments to `Unit`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InitBlock(nn.Module):\n",
    "    \"Init block of folded ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold:int, stride:int=1, **kwargs):\n",
    "        super(InitBlock, self).__init__()\n",
    "        self.ni, self.fold = ni, fold\n",
    "        units = []\n",
    "        for i in range(fold-1):\n",
    "            units += [Unit(ni, stride=stride, **kwargs)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xs = [x]\n",
    "        for i in range(self.fold-1):\n",
    "            xs += [xs[i] + self.units[i](xs[i])]\n",
    "        xs.reverse()\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([2, 16, 32, 32]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = InitBlock(mbconv, 16, 4, stride=1, nh=32)\n",
    "x = torch.randn(2,16,32,32)\n",
    "xs = m(x)\n",
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FoldBlock(nn.Module):\n",
    "    \"Basic block of folded ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold:int, stride:int=1, **kwargs):\n",
    "        super(FoldBlock, self).__init__()\n",
    "        self.ni, self.fold, self.stride = ni, fold, stride\n",
    "        units = []\n",
    "        for i in range(fold-1):\n",
    "            units += [Unit(ni, stride=1, **kwargs)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        \n",
    "    def forward(self, *xs):\n",
    "        xs = list(xs)\n",
    "        for i in range(self.fold-1):\n",
    "            xs[i+1] = xs[i+1] + self.units[i](xs[i])\n",
    "        xs.reverse()\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = FoldBlock(mbconv, 16, 4, nh=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs2 = m(*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " torch.Size([2, 16, 32, 32]),\n",
       " torch.Size([2, 16, 32, 32]),\n",
       " torch.Size([2, 16, 32, 32]),\n",
       " torch.Size([2, 16, 32, 32]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs2),xs2[0].shape,xs2[1].shape,xs2[2].shape,xs2[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExpandBlock(nn.Module):\n",
    "    \"Expand block of folded ResNet\"\n",
    "    def __init__(self, Unit:nn.Module, ni:int, fold1:int, fold2:int, stride:int=1, **kwargs):\n",
    "        super(ExpandBlock, self).__init__()\n",
    "        self.ni, self.fold1, self.fold2, self.stride = ni, fold1, fold2, stride\n",
    "        units = []\n",
    "        for i in range(fold2 - fold1):\n",
    "            units += [Unit(ni, stride=1, **kwargs)]\n",
    "        self.units = nn.ModuleList(units)\n",
    "        if stride == 2:\n",
    "            self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, *xs):\n",
    "        xs = list(xs)\n",
    "        if self.stride == 2:\n",
    "            for i in range(len(xs)):\n",
    "                xs[i] = self.pool(xs[i])\n",
    "        xs.reverse()\n",
    "        for i in range(self.fold2 - self.fold1):\n",
    "            xs.append(self.units[i](xs[-1]) + xs[-1])\n",
    "        xs.reverse()\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ExpandBlock(mbconv, 16, fold1=4, fold2=8, stride=2, nh=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs2 = m(*xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " torch.Size([2, 16, 16, 16]),\n",
       " torch.Size([2, 16, 16, 16]),\n",
       " torch.Size([2, 16, 16, 16]),\n",
       " torch.Size([2, 16, 16, 16]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs2),xs2[0].shape,xs2[1].shape,xs2[2].shape,xs2[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNetX2(nn.Module):\n",
    "    \"A folded resnet.\"\n",
    "    def __init__(self, Stem, Unit, fold:int, ni:int, num_nodes:tuple, exp:int=1,\n",
    "                 bottle_scale:int=1, first_downsample:bool=False,\n",
    "                 c_in:int=3, c_out:int=10, **kwargs):\n",
    "        super(ResNetX2, self).__init__()\n",
    "        num_stages = len(num_nodes)\n",
    "        nh = ni * bottle_scale\n",
    "        strides = [1 if i==0 and not first_downsample else 2 for i in range(num_stages)]\n",
    "        folds = [1] + [fold*exp**i for i in range(num_stages)]\n",
    "        \n",
    "        self.stem = Stem(c_in, no=ni) # , deep_stem\n",
    "        #self.init = InitBlock(Unit, ni, fold, nh=nh)\n",
    "        \n",
    "        units = []\n",
    "        idmappings = []\n",
    "        cur = 1\n",
    "        for i, (nu, stride) in enumerate(zip(num_nodes, strides)):\n",
    "            for j in range(nu):\n",
    "                if j == 0: # the first node(layer) of each stage\n",
    "                    units += [ExpandBlock(Unit, ni, fold1 = folds[i], fold2=folds[i+1], stride=stride, nh=nh, **kwargs)]\n",
    "                else:\n",
    "                    units += [FoldBlock(Unit, ni, fold=folds[i+1], stride=1, nh=nh, **kwargs)]\n",
    "                    \n",
    "        self.units = nn.ModuleList(units)\n",
    "        \n",
    "        self.classifier = Classifier(ni*folds[-1], c_out) #*fold\n",
    "        self.fold = fold\n",
    "        self.num_nodes = num_nodes\n",
    "        init_cnn(self)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        xs = [x] #self.init(x)\n",
    "        for unit in self.units:\n",
    "            xs = unit(*xs)\n",
    "        x = torch.cat(xs,1)  #xs[0] \n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7710794)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = [8]*4\n",
    "model = ResNetX2(Stem=conv_bn, Unit=mbconv, fold=4, ni=64, num_nodes=num_nodes, exp=2, bottle_scale=2)\n",
    "num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    out = model(x)\n",
    "    out.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
